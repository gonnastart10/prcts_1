@@ -0,0 +1,590 @@
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Априори алгоритм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "from optparse import OptionParser\n",
    "\n",
    "\n",
    "def subsets(arr):\n",
    "    \"\"\" Returns non empty subsets of arr\"\"\"\n",
    "    return chain(*[combinations(arr, i + 1) for i, a in enumerate(arr)])\n",
    "\n",
    "\n",
    "def returnItemsWithMinSupport(itemSet, transactionList, minSupport, freqSet):\n",
    "        \"\"\"calculates the support for items in the itemSet and returns a subset\n",
    "       of the itemSet each of whose elements satisfies the minimum support\"\"\"\n",
    "        _itemSet = set()\n",
    "        localSet = defaultdict(int)\n",
    "\n",
    "        for item in itemSet:\n",
    "                for transaction in transactionList:\n",
    "                        if item.issubset(transaction):\n",
    "                                freqSet[item] += 1\n",
    "                                localSet[item] += 1\n",
    "\n",
    "        for item, count in localSet.items():\n",
    "                support = float(count)/len(transactionList)\n",
    "\n",
    "                if support >= minSupport:\n",
    "                        _itemSet.add(item)\n",
    "\n",
    "        return _itemSet\n",
    "\n",
    "\n",
    "def joinSet(itemSet, length):\n",
    "        \"\"\"Join a set with itself and returns the n-element itemsets\"\"\"\n",
    "        return set([i.union(j) for i in itemSet for j in itemSet if len(i.union(j)) == length])\n",
    "\n",
    "\n",
    "def getItemSetTransactionList(data_iterator):\n",
    "    transactionList = list()\n",
    "    itemSet = set()\n",
    "    for record in data_iterator:\n",
    "        transaction = frozenset(record)\n",
    "        transactionList.append(transaction)\n",
    "        for item in transaction:\n",
    "            itemSet.add(frozenset([item]))              # Generate 1-itemSets\n",
    "    return itemSet, transactionList\n",
    "\n",
    "\n",
    "def runApriori(data_iter, minSupport, minConfidence):\n",
    "    \"\"\"\n",
    "    run the apriori algorithm. data_iter is a record iterator\n",
    "    Return both:\n",
    "     - items (tuple, support)\n",
    "     - rules ((pretuple, posttuple), confidence)\n",
    "    \"\"\"\n",
    "    itemSet, transactionList = getItemSetTransactionList(data_iter)\n",
    "\n",
    "    freqSet = defaultdict(int)\n",
    "    largeSet = dict()\n",
    "    # Global dictionary which stores (key=n-itemSets,value=support)\n",
    "    # which satisfy minSupport\n",
    "\n",
    "    assocRules = dict()\n",
    "    # Dictionary which stores Association Rules\n",
    "\n",
    "    oneCSet = returnItemsWithMinSupport(itemSet,\n",
    "                                        transactionList,\n",
    "                                        minSupport,\n",
    "                                        freqSet)\n",
    "\n",
    "    currentLSet = oneCSet\n",
    "    k = 2\n",
    "    while(currentLSet != set([])):\n",
    "        largeSet[k-1] = currentLSet\n",
    "        currentLSet = joinSet(currentLSet, k)\n",
    "        currentCSet = returnItemsWithMinSupport(currentLSet,\n",
    "                                                transactionList,\n",
    "                                                minSupport,\n",
    "                                                freqSet)\n",
    "        currentLSet = currentCSet\n",
    "        k = k + 1\n",
    "\n",
    "    def getSupport(item):\n",
    "            \"\"\"local function which Returns the support of an item\"\"\"\n",
    "            return float(freqSet[item])/len(transactionList)\n",
    "\n",
    "    toRetItems = []\n",
    "    for key, value in largeSet.items():\n",
    "        toRetItems.extend([(tuple(item), getSupport(item))\n",
    "                           for item in value])\n",
    "\n",
    "    toRetRules = []\n",
    "    for key, value in largeSet.items()[1:]:\n",
    "        for item in value:\n",
    "            _subsets = map(frozenset, [x for x in subsets(item)])\n",
    "            for element in _subsets:\n",
    "                remain = item.difference(element)\n",
    "                if len(remain) > 0:\n",
    "                    confidence_lift = []\n",
    "                    confidence_lift.append(getSupport(item)/getSupport(element))\n",
    "                    confidence_lift.append(getSupport(item)/(getSupport(element)*getSupport(remain)))\n",
    "                    if confidence_lift[0] >= minConfidence:\n",
    "                        toRetRules.append(((tuple(element), tuple(remain)),\n",
    "                                           confidence_lift))\n",
    "    return toRetItems, toRetRules\n",
    "\n",
    "\n",
    "\n",
    "def dataFromFile(fname):\n",
    "        \"\"\"Function which reads from the file and yields a generator\"\"\"\n",
    "        file_iter = open(fname, 'rU')\n",
    "        for line in file_iter:\n",
    "                line = line.strip().rstrip(',')                         # Remove trailing comma\n",
    "                record = frozenset(line.split(','))\n",
    "                yield record\n",
    "                \n",
    "def printResults(items, rules, rs,it):\n",
    "    \"\"\"prints the generated itemsets sorted by support and the confidence rules sorted by confidence\"\"\"\n",
    "    if len(rules)!=0:\n",
    "        rs.write(\"SUP------------SUP------------SUP:\\n\")\n",
    "        rs.write(\"For time boundaries on: \"+it+\"\\n\") #показывает периоды какого пака исследуются\n",
    "        for item, support in sorted(items, key=lambda (item, support): support):\n",
    "            rs.write(\"item: %s , %.3f \\n\" % (str(item), support))\n",
    "            #print \"item: %s , %.3f\" % (str(item), support)\n",
    "        rs.write(\"\\nRULES------------RULES------------RULES:\\n\")\n",
    "        for rule, confidence in sorted(rules, key=lambda (rule, confidence): confidence):\n",
    "            pre, post = rule\n",
    "            rs.write(\"Rule: %s ==> %s , confidence: %.3f, lift: %.3f\\n\" % (str(pre), str(post), confidence[0], confidence[1]))\n",
    "        rs.write(\"\\n-----------------------------------------\\n\")\n",
    "        rs.write(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    optparser = OptionParser()\n",
    "    optparser.add_option('-f', '--inputFile',\n",
    "                         dest='input',\n",
    "                         help='filename containing csv',\n",
    "                         default=None)\n",
    "    optparser.add_option('-s', '--minSupport',\n",
    "                         dest='minS',\n",
    "                         help='minimum support value',\n",
    "                         default=0.15,\n",
    "                         type='float')\n",
    "    optparser.add_option('-c', '--minConfidence',\n",
    "                         dest='minC',\n",
    "                         help='minimum confidence value',\n",
    "                         default=0.6,\n",
    "                         type='float')\n",
    "\n",
    "    (options, args) = optparser.parse_args()\n",
    "\n",
    "\n",
    "    inFile = dataFromFile(\"without_bound.csv\")\n",
    "\n",
    "    minSupport = options.minS\n",
    "    minConfidence = options.minC\n",
    "\n",
    "    items, rules = runApriori(inFile, minSupport, minConfidence)\n",
    "\n",
    "    #printResults(items, rules)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Всевозможные паки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "#social_netork='fb'\n",
    "pcks=[]\n",
    "with open('trans.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "    pcks=[]\n",
    "    spamreader.next()\n",
    "    for row in spamreader:\n",
    "        if (row[5] not in pcks):\n",
    "            pcks.append(row[5])\n",
    "    print len(pcks)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Априори для нашего файла с названиями паков. Для каждого пака определяется акционный он или нет и, если он акционный, то для всех периодов вычисляются ассоциативные правила. Соответсвенно возможны пересечения результатов (некоторые акции запускаются в одно и то же время)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def write_res_to_file_name(file_name, mnsp, mncf):\n",
    "    now = datetime.now()\n",
    "    minSupport=mnsp\n",
    "    minConfidence=mncf\n",
    "    \n",
    "    count=0\n",
    "    with open(file_name, 'w') as rs:\n",
    "        for it in pcks:\n",
    "            times=[]\n",
    "            # 1) составляем временные промежутки для паков\n",
    "\n",
    "            with open('trans.csv', 'rb') as csvfile:\n",
    "                spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "                spamreader.next()\n",
    "                for row in spamreader:\n",
    "                    if row[5]==it:\n",
    "                        times.append(int(row[2]))\n",
    "\n",
    "            difference=172800+43200 # = 2.5 days in seconds\n",
    "            # сравниваем даты по timestamp\n",
    "            # если покупки наблюдались в окрестности 2х дней, то\n",
    "            # будем считать, что в эти дни акция действовала\n",
    "            times.sort()\n",
    "\n",
    "            start_time=[]\n",
    "            end_time=[]\n",
    "\n",
    "            beg=times[0]\n",
    "\n",
    "            start_time.append(beg)\n",
    "            for item in times:\n",
    "                if beg+difference>=item:\n",
    "                    beg=item\n",
    "                else:\n",
    "                    start_time.append(item)\n",
    "                    end_time.append(beg)\n",
    "                    beg=item\n",
    "            end_time.append(beg)\n",
    "\n",
    "            # 2) проверяем временные промежутки; если все промежутки лежат в рамках 2.5 недель,\n",
    "            # то считаем пак акционным и проходимся априори алгоритмом по выявленным промежуткам\n",
    "\n",
    "            week_time=604800 # week time\n",
    "            access=True\n",
    "            for i in range(0,len(start_time)):\n",
    "                if end_time[i]-start_time[i] > week_time*2.5: # предполагаем, что акции длятся не более 2х с половиной недель\n",
    "                    access=False\n",
    "                    count=count+1\n",
    "\n",
    "            if access==True:\n",
    "                for bound in range(0,len(start_time)):\n",
    "                    ids={}\n",
    "                    # 3) если пак акционный, то забиваем данные для составления ассоциативных правил\n",
    "\n",
    "                    with open('trans.csv', 'rb') as csvfile:\n",
    "                        spam = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "                        spam.next()\n",
    "                        for row in spam:\n",
    "                            if (int(row[2])>=start_time[bound] and int(row[2])<=end_time[bound]):\n",
    "                                if ids.has_key(int(row[0]))==True:\n",
    "                                    val=ids.get(int(row[0]))\n",
    "                                    if row[5] not in val:\n",
    "                                        val.append(row[5])\n",
    "                                else:\n",
    "                                    ids[int(row[0])]=[]# каждый id принимает в значение свои транзакции\n",
    "                                    ids[int(row[0])].append(row[5])\n",
    "\n",
    "                    with open('file_for_transactions.csv', 'w') as csf:\n",
    "                        for key, value in ids.items():\n",
    "                            st=\"\"\n",
    "                            for i in range(0,len(value)):\n",
    "                                st=st+value[i]+','\n",
    "                            csf.write(st+'\\n')\n",
    "                    #now1 = datetime.now()\n",
    "                    #print \"файлы: \",\"  \",(now1-now)\n",
    "\n",
    "                    inFile = dataFromFile(\"file_for_transactions.csv\")\n",
    "                    items, rules = runApriori(inFile, minSupport, minConfidence)    \n",
    "                    printResults(items, rules, rs,it)\n",
    "\n",
    "\n",
    "    # 4) время работы алгоритма\n",
    "    now1 = datetime.now()\n",
    "    print (now1-now)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Соответсвенно запускаем априори на наших данные. Подаем название файла, в который записываются результаты, minSupport, minConfidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:04:42.642291\n"
     ]
    }
   ],
   "source": [
    "write_res_to_file_name(\"res_l1.txt\", 0.2, 0.7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Csv библиотека не воспринимает \"||\", поэтому добавляем пробелы между каждыми \"||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count=1\n",
    "with open('w_pinfo.csv', 'w') as csv:\n",
    "    with open('wlitems_pinfo.csv', 'rb') as csvfile:\n",
    "        for line in csvfile:\n",
    "                temp=\"\"\n",
    "                if \"||\" in line:\n",
    "                    for i in range(0,len(line)):\n",
    "                        temp=temp+line[i]\n",
    "                        if i!=len(line)-1 and line[i]==\"|\":\n",
    "                            if line[i+1]==\"|\":\n",
    "                                temp=temp+\" \"\n",
    "                    csv.write(temp)\n",
    "                else:\n",
    "                    csv.write(line)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создаем словарь айди-соц данные. Пока что тут лежит только страна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erros has been found\n",
      "0:00:05.777879\n",
      "0:00:01.784865\n"
     ]
    }
   ],
   "source": [
    "import sys, errno\n",
    "\n",
    "now = datetime.now()\n",
    "# 4 - country\n",
    "id_soc_data={}\n",
    "with open('w_pinfo.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "    spamreader.next()\n",
    "    for row in spamreader:\n",
    "        try:\n",
    "            if id_soc_data.has_key(int(row[0]))==False:\n",
    "                id_soc_data[int(row[0])]=[]\n",
    "                id_soc_data[int(row[0])].append(row[5])\n",
    "        except ValueError as e:\n",
    "            print(\"Error has been found\") #вылез странный айдишник 2.392...Е, пока что кидаю в еррор\n",
    "            now1 = datetime.now()\n",
    "            print(now1-now)\n",
    "            now = datetime.now()\n",
    "now1 = datetime.now()\n",
    "print (now1-now)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Априори на наших данных+страна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def write_res_to_file_name_with_additional_data(file_name, mnsp, mncf):\n",
    "    now = datetime.now()\n",
    "    minSupport=mnsp\n",
    "    minConfidence=mncf\n",
    "    \n",
    "    count=0\n",
    "    with open(file_name, 'w') as rs:\n",
    "        for it in pcks:\n",
    "            times=[]\n",
    "            # 1) составляем временные промежутки для паков\n",
    "\n",
    "            with open('trans.csv', 'rb') as csvfile:\n",
    "                spamreader = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "                spamreader.next()\n",
    "                for row in spamreader:\n",
    "                    if row[5]==it:\n",
    "                        times.append(int(row[2]))\n",
    "\n",
    "            difference=172800+43200 # = 2.5 days in seconds\n",
    "            # сравниваем даты по timestamp\n",
    "            # если покупки наблюдались в окрестности 2х дней, то\n",
    "            # будем считать, что в эти дни акция действовала\n",
    "            times.sort()\n",
    "\n",
    "            start_time=[]\n",
    "            end_time=[]\n",
    "\n",
    "            beg=times[0]\n",
    "\n",
    "            start_time.append(beg)\n",
    "            for item in times:\n",
    "                if beg+difference>=item:\n",
    "                    beg=item\n",
    "                else:\n",
    "                    start_time.append(item)\n",
    "                    end_time.append(beg)\n",
    "                    beg=item\n",
    "            end_time.append(beg)\n",
    "\n",
    "            # 2) проверяем временные промежутки; если все промежутки лежат в рамках 2.5 недель,\n",
    "            # то считаем пак акционным и проходимся априори алгоритмом по выявленным промежуткам\n",
    "\n",
    "            week_time=604800 # week time\n",
    "            access=True\n",
    "            for i in range(0,len(start_time)):\n",
    "                if end_time[i]-start_time[i] > week_time*2.5: # предполагаем, что акции длятся не более 2х с половиной недель\n",
    "                    access=False\n",
    "                    count=count+1\n",
    "\n",
    "            if access==True:\n",
    "                for bound in range(0,len(start_time)):\n",
    "                    ids={}\n",
    "                    # 3) если пак акционный, то забиваем данные для составления ассоциативных правил\n",
    "\n",
    "                    with open('trans.csv', 'rb') as csvfile:\n",
    "                        spam = csv.reader(csvfile, delimiter='|', quotechar='|')\n",
    "                        spam.next()\n",
    "                        for row in spam:\n",
    "                            if (int(row[2])>=start_time[bound] and int(row[2])<=end_time[bound]):\n",
    "                                if ids.has_key(int(row[0]))==True:\n",
    "                                    val=ids.get(int(row[0]))\n",
    "                                    if row[5] not in val:\n",
    "                                        val.append(row[5])\n",
    "                                else:\n",
    "                                    ids[int(row[0])]=[]# каждый id принимает в значение свои транзакции\n",
    "                                    ids[int(row[0])].append(row[5])\n",
    "                    \n",
    "                    with open('file_for_transactions.csv', 'w') as csf:\n",
    "                        for key, value in ids.items():\n",
    "                            st=\"\"\n",
    "                            for i in range(0,len(value)):\n",
    "                                st=st+value[i]+','\n",
    "                            if id_soc_data.has_key(key):\n",
    "                                if id_soc_data[key][0]!=\" \":    \n",
    "                                    st=st+id_soc_data[key][0]+\",\"\n",
    "                            csf.write(st+'\\n')\n",
    "                    #now1 = datetime.now()\n",
    "                    #print \"файлы: \",\"  \",(now1-now)\n",
    "\n",
    "                    inFile = dataFromFile(\"file_for_transactions.csv\")\n",
    "                    items, rules = runApriori(inFile, minSupport, minConfidence)    \n",
    "                    printResults(items, rules, rs, it)\n",
    "\n",
    "\n",
    "    # 4) время работы алгоритма\n",
    "    now1 = datetime.now()\n",
    "    print (now1-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:04:28.286215\n"
     ]
    }
   ],
   "source": [
    "write_res_to_file_name_with_additional_data(\"res_ad_data_l1.txt\", 0.2, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
